# LLM - Local Models
transformers>=4.40.0      # for local model inference with DeepSeek and Llama
torch>=2.2.0              # backend for transformers
accelerate>=0.22.0        # helps with large models and GPU support
huggingface-hub>=0.20.0   # model downloading
bitsandbytes>=0.41.0      # for 4-bit quantization
scipy>=1.10.0             # often needed for some model loadings

# NLP
sentence-transformers>=2.2.2
vaderSentiment>=3.3.2
scikit-learn>=1.3.0

# HTTP
requests>=2.31.0

# Utilities
python-dotenv>=1.0.0
pyyaml>=6.0
click>=8.1.0
rich>=13.7.0
tenacity>=8.2.0
